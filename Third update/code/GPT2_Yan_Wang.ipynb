{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT2_Yan Wang.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9h6RU3w4ky8d",
        "outputId": "53bd7888-48fd-4690-9a3b-2942191f65e5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hN2K4Wp0qZh",
        "outputId": "86d0a734-de0e-497e-8433-394549ba5e7e"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Aug 10 09:27:49 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tq6oPDfN1wNC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e725e118-c3b4-4616-b24e-76eec5afee3e"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "import os\n",
        "import requests\n",
        "import re"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxUKVFKmt0u1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "539e8af7-6e8d-42ad-bd30-5de52267da9d"
      },
      "source": [
        "# download gpt2 models.  \n",
        "gpt2.download_gpt2(model_name=\"124M\")\n",
        "gpt2.download_gpt2(model_name=\"355M\")\n",
        "#gpt2.download_gpt2(model_name=\"774M\")\n",
        "#gpt2.download_gpt2(model_name=\"1558M\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 575Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:01, 971kit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 714Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:46, 10.6Mit/s]\n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 662Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 1.14Mit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 1.16Mit/s]\n",
            "Fetching checkpoint: 1.05Mit [00:00, 678Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:01, 950kit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 604Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [03:27, 6.85Mit/s]\n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 353Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:01, 951kit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 1.14Mit/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwdJWDEdAZof"
      },
      "source": [
        "legacy:  \n",
        "If dataset hasn't been created and splited to train & test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUSMnpAiWeFL"
      },
      "source": [
        "#  copy models to google drive if you want\n",
        "!cp -r /content/models /content/drive/MyDrive "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0FPqyGMoezw"
      },
      "source": [
        "# load dataset\n",
        "file_name = \"HarryPotter.txt\"\n",
        "\n",
        "# if no dataset here, create a HarryPotter dataset\n",
        "if not os.path.isfile(file_name):\n",
        "\turl = \"https://raw.githubusercontent.com/YanWang20121865/MSc2021YanWang/main/Second%20update/Dataset/HarryPotter.txt\"\n",
        "\tdata = requests.get(url)\n",
        "\t\n",
        "\twith open(file_name, 'w') as f:\n",
        "\t\tf.write(data.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjmuAW7b4Lwk"
      },
      "source": [
        "!export PYTHONIOENCODING=UTF-8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZBHh4BDA6cO"
      },
      "source": [
        "def train_test_split_fun(file_name, num):\n",
        "  if 0 < num < 1:\n",
        "    # open original txt file\n",
        "    text = open(file_name+'.txt',\"r\", encoding='UTF-8').read()    \n",
        "    # split each line of content in text file \n",
        "    b=re.split('\\n',text)\n",
        "\n",
        "    # check how many lines in total\n",
        "    n=0\n",
        "    for i in b:\n",
        "      n+=1\n",
        "    print(n)\n",
        "\n",
        "    # generage train.txt and test.txt files\n",
        "    f1 = open(file_name+'_train.txt','a')\n",
        "    f2 = open(file_name+'_test.txt','a')\n",
        "    m=0\n",
        "    for i in b:\n",
        "      m+=1\n",
        "      if m<=n*num:    # train : test = num\n",
        "        f1.write(i)\n",
        "      else:\n",
        "        f2.write(i)\n",
        "    #close files\n",
        "    f1.close()\n",
        "    f2.close()\n",
        "  else:\n",
        "    print(\"The training data ratio must between 0 and 1.0! \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IKzDzooBDev"
      },
      "source": [
        "# code for spliting train & test dataset\n",
        "num = 0.8\n",
        "file_name = 'HarryPotter'\n",
        "train_test_split_fun(file_name, num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9PaFqHSAjpX"
      },
      "source": [
        "copy dataset from google drive here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjW1SdhdAYSZ"
      },
      "source": [
        "# copy datasets \n",
        "!cp -r /content/drive/MyDrive/Dataset/* /content"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QogIqDMtH181"
      },
      "source": [
        "For restart training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2wMZYJrij2A"
      },
      "source": [
        "# load checkpoint to google drive if in need( if you want to restart training from existed checkpoint)\n",
        "!cp -r /content/drive/MyDrive/checkpoint/ /content/checkpoint/"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "321S_Qo4B50I"
      },
      "source": [
        "# set file name and model_name for training and generating\n",
        "file_name = 'dataset_top1000'\n",
        "model_name = '355M'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kwMRWI_HCiw"
      },
      "source": [
        "###Train model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bszlok5-3ZW3"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name+'_train.txt',\n",
        "              model_name=model_name,\n",
        "              steps=10000,\n",
        "              #Set to fresh to start training from the base GPT-2, or set to latest to restart training from an existing checkpoint.\n",
        "              restore_from='latest',   \n",
        "              run_name='run_'+model_name+'_'+file_name,\n",
        "              print_every=10,\n",
        "              sample_every=250,\n",
        "              save_every=500,\n",
        "              \n",
        "              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiSiwgGC7Yhv"
      },
      "source": [
        "# save checkpoint to google drive \n",
        "!cp -r /content/checkpoint/ /content/drive/MyDrive"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3qoWxSRJaFT"
      },
      "source": [
        "###Generate story txt file:  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHxe-FtT7xc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bb43a40-7a8a-4ab5-b670-173e0e4cc419"
      },
      "source": [
        "# load the model we trained\n",
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name='run_'+model_name+'_'+file_name)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading checkpoint checkpoint/run_355M_dataset_top1000/model-69501\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/run_355M_dataset_top1000/model-69501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhu2NN3O8C2J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05368aca-33e3-4053-8229-b7f16276d1ae"
      },
      "source": [
        "# generate txt files to save stories\n",
        "# path for generated file\n",
        "gen_file = '/content/drive/MyDrive/Generated Story/run_'+model_name+'_'+file_name+'/{:%Y%m%d_%H%M%S}.txt'.format(datetime.utcnow())\n",
        "start = input(\"Starting sentence:\")\n",
        "gpt2.generate_to_file(sess,\n",
        "                      run_name='run_'+model_name+'_'+file_name,\n",
        "                      destination_path=gen_file,\n",
        "                      prefix=start,  # input starting sentence\n",
        "                      length=800,   # set max length of generated story\n",
        "                      temperature=0.9,  # The higher the temperature, the crazier the text\n",
        "                      nsamples=1,   # set number of generated stories, can generate several samples simultaneously\n",
        "                      batch_size=1,\n",
        "                      )\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting sentence:Welcome to University of Limerick\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5B1l7Zn2mIK"
      },
      "source": [
        "# may have to run twice to get file to download\n",
        "files.download(gen_file)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}